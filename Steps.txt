- Create Platform Service with Service Ops (GetPlatforms, GetPlatformById, CreatePlatform)
    - Test Platform Service Ops in Postman
    - Create Docker File and run docker for Platform Service (https://docs.docker.com/samples/dotnetcore/)
    - Test Platform Service Ops in Postman for Docker
    - Create Kubernate deployment file for Platform Service
    - Create kubernate node service deployment file for Platform Service
    - Test Platform Service Ops in Postman for Kubernetes
- Create CommandService with Service Ops
    - Test Service Ops in Postman
- Update Platform Service to support messaging (SyncDataServices)
    -- Create Interface and Service for HttpClient
    -- Add services.AddHttpClient<ICommandDataClient, HttpCommandDataClient>(); in startup
    -- Update PlatformController to support messaging
- Create Docker File and run docker for Command Service
- Update platforms-depl.yaml file to support cluster IP
- Create new appsettings.production.json in platform service and update command service entry point from k8s ClusterIP name
    -- Build platform service docker and push it
    -- Redeploy platform service again in kubernate
    -- Restart exisitng deployments in kubernate
    -- Apply command service deployments in k8s
- Integrating ingress nginx
    -- google ingress nginx
    -- open https://kubernetes.github.io/ingress-nginx/deploy/#docker-desktop
    -- copy network load balancer for docker and run -- kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.1.0/deploy/static/provider/aws/deploy.yaml
    -- Run kubectl get namespace to see all like nginx
    -- Create ingress routing deployment file -- ingress-srv.yaml
    -- Add host entry (acme.com as mentioned in ingress-srv.yaml) in c:\windows\system32\driver\host file
        -- # Added by Siva for microservices r&d project
        -- 127.0.0.1 acme.com
    -- Deploy ingress-srv.yaml using - kubectl apply -f ingress-srv.yaml    
- Implement Persistent Volume Claim support & mssql
    -- Create new local-pvc.yaml in k8s
    -- kubectl apply -f local-pvc.yaml
    -- kubectl get pvc
    -- kubectl create secret generic mssql --from-literal=SA_PASSWORD="pa55w0rd!"
    -- create mssql-plat-depl.yaml file dedicated to platform services
    -- kubectl apply -f mssql-plat-depl.yaml .. this will do mssql deployment/ cluster ip/ load balancer
    -- Add SQL Server Connection string and update startup class with production and dev environment connections
    -- Create migrations only for production
    -- Generate migrations - dotnet ef migrations add initialmigration
    -- build docker build âžœ  docker build -t siva4dockerstore/platformservice . and publish
    -- restart kube deployment
- Update CommandService
    -- Create Models Platform/Command
    -- Add DbContext, CommandRepo, DTOs, Profiles, DbContext in start up, ICommandRepo in start up
    -- Add service ops in CommandService --> PlatformController, CommandController
- RabbitMQ
    -- Create RabbitMQ deployment file and run kubectl
    -- Try login http://localhost:15672 -- guest/guest
    -- Add RabbitMQ reference in PlatformService ... 
    -- Add RabbitHost in config both dev and prod
    -- Create PlatformPublishedDto and update Automapper profile
    -- Create AsyncDataServices --> IMessageBusClient,MessageBusClient and register in startup DI
    -- Update PlatformController in Platform Service for AsyncMessaging
    -- Test Service
    -- Add RabbitMQ reference in CommandService
    -- Add RabbitHost in config both dev and prod in CommandService
    -- Create PlatformPublishedDto/GenericEventDto and update Automapper profile
    -- Update ICommandRepo/ CommandRepo 
    -- Create EventProcessing folder for RabbitMQ events and further development
    -- Add services.AddSingleton<IEventProcessor, EventProcessor>();
    -- Create AsyncDataServices folder and write MessageBusSubscriber class
    -- Add services.AddHostedService<MessageBusSubscriber>();
    -- Test CreatePlatform from PlatformService and check PlatformService and CommandService Console for messages
    -- Run GetAllPlatforms in postman from CommandService and CreateCommandForPlatform
    -- Build docker for both the services
    -- Redeploy both the services in kubernetes deployments
- gRPC
    -- Updte ports in platforms-depl.yaml file in kubernetes, since config changes redeploy .depl file of platform
    -- Add kestrel settings in platdorm service appsettings.production file
    -- Add reference of Grpc.AspNetCore to platform service
    -- To support gRPC in command service we need to add few references like Grpc.Tools, Grpc.Net.Client and Google.Protobuf
    -- Start development Grpc Server in Platform Service
    -- Crete Protos folder in Platform Service and platforms.proto
    -- Update PlatformService.csproj with created proto details in ItemGroup as Server  .... build project and check obj for auto generated proto
    -- Update PlatformService profile ... CreateMap<Platform, GrpcPlatformModel>()
    -- Create Grpc folder in SyncDataServices and GrpcPlatformService.cs
    -- Register grpc in StartUp .. services.AddGrpc(); and endpoints.MapGrpcService<GrpcPlatformService>();
    -- Start development Grpc client in CommandService
    -- Update appsettings .production/development for grpc
    -- Crete Protos folder in command Service and platforms.proto (copy content same from platform service)
    -- Update CommandService.csproj with created proto details in ItemGroup as Client .... build project and check obj for auto generated proto
    -- Update CommandService profile ... CreateMap<GrpcPlatformModel,Platform>()
    -- Create SyncDataServices\Grpc\IPlatformDataClient and its implementation
    -- Register services.AddScoped<IPlatformDataClient, PlatformDataClient>(); in startup
    -- Create PreDb seed data class and call it in startup
    -- Build and run both services and test in postman with local get all platforms and create a new 
    -- Build both service docker builds and restart kubernetes deployments
- End